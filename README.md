# YouTube Chatbot using LangChain (RAG)

Overview
- This repository contains a Jupyter notebook and an autogenerated Python script that implement a Retrieval-Augmented Generation (RAG) pipeline for building a YouTube transcript-based chatbot using LangChain.

What's included
- `rag_using_langchain.ipynb` — original Jupyter notebook used for development.
- `rag_using_langchain.py` — autogenerated script converted from the notebook (code cells preserved, markdown converted to comments).

Summary of the pipeline
- 1) Fetch YouTube captions using `youtube-transcript-api`.
- 2) Normalize and flatten the transcript into a single string (robust to dicts and objects with `.text`).
- 3) Split transcript into chunks with `RecursiveCharacterTextSplitter`.
- 4) Create embeddings (HuggingFace `sentence-transformers/all-MiniLM-L6-v2`) and store them in a FAISS vectorstore.
- 5) Build a retriever and augment queries with retrieved context.
- 6) Use a chat model (example: `ChatOllama`) to generate answers from retrieved context.

Key files and locations
- Notebook: `c:/My Files/YouTube Chatbot using Langchain/rag_using_langchain.ipynb`
- Script: `c:/My Files/YouTube Chatbot using Langchain/rag_using_langchain.py`

Security note
- The autogenerated script currently contains an inline OpenAI API key copied from the notebook. Remove or rotate this key before sharing or committing. Prefer using environment variables or a `.env` file.

Quick setup
1. Create and activate a Python environment (recommended).
2. Install required packages:

```powershell
pip install youtube-transcript-api langchain-community langchain-openai faiss-cpu tiktoken python-dotenv sentence-transformers torch
```

3. (Optional) Install CPU-only PyTorch if needed:

```powershell
pip install --index-url https://download.pytorch.org/whl/cpu torch
```

Run the script

```powershell
python "c:/My Files/YouTube Chatbot using Langchain/rag_using_langchain.py"
```

Notes & next steps
- After running, verify the transcript printout (script prints the first 1000 characters). Then continue with embedding creation and retrieval.
- Consider removing the inline API key and moving configuration to a `.env` file read by `python-dotenv`.
- If you'd like, I can: remove the embedded key, create a `requirements.txt`, or run a quick syntax check on the script.

Maintainer
- Created automatically from the notebook on Feb 3, 2026.
