# Building a YouTube Chatbot with LangChain (RAG)

**TL;DR**
- I built a Retrieval-Augmented Generation (RAG) pipeline that ingests YouTube captions, builds embeddings, and answers user questions grounded in the video transcript using LangChain and FAISS.

**Why this project?**
- YouTube videos contain rich, searchable information but their content isn’t queryable out-of-the-box. A RAG approach makes video content explorable: fetch captions, embed meaningful chunks, retrieve relevant context, and generate answers grounded in the transcript.

**What I built**
- A compact RAG prototype implemented as a Jupyter notebook (`rag_using_langchain.ipynb`) and converted into a runnable script (`rag_using_langchain.py`). The pipeline:
  - Fetches captions via `youtube-transcript-api`.
  - Normalizes and flattens the transcript into a single string.
  - Splits the transcript into overlapping chunks with `RecursiveCharacterTextSplitter`.
  - Produces embeddings with `sentence-transformers/all-MiniLM-L6-v2` (via `HuggingFaceEmbeddings`).
  - Stores embeddings in a FAISS vectorstore and exposes a retriever.
  - Uses a chat model (example: `ChatOllama`) to generate answers from the retrieved context.

**Architecture & flow**
- Ingest: fetch captions for a YouTube `video_id`.
- Normalize: robustly flatten the returned `transcript_list` (handles dicts or objects with `.text`).
- Chunk: split long transcripts into overlapping chunks suitable for embedding.
- Embed + Index: compute embeddings and insert into FAISS.
- Retrieve: a user query uses the retriever to return the top-k chunks.
- Augment + Generate: combine retrieved chunks into context and pass to an LLM for an answer constrained to the context.

**Key files**
- `rag_using_langchain.ipynb` — original, interactive notebook used during development.
- `rag_using_langchain.py` — autogenerated script with the same code cells (markdown converted to comments).
- `README.md` — setup and quick notes (already in the repo).

**Important implementation notes**
- The script includes a robust transcript flattening snippet that converts the API result to a list, then extracts `text` either via `item.get("text")` for dicts or `getattr(item, "text")` for objects, and joins non-empty entries.
- Chunks are produced with `RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)` to balance context size and overlap for retrieval.

**Setup (quick)**
1. Create a virtual environment and activate it.
2. Install the dependencies:

```powershell
pip install youtube-transcript-api langchain-community langchain-openai faiss-cpu tiktoken python-dotenv sentence-transformers torch
```

3. Run the script:

```powershell
python "c:/My Files/YouTube Chatbot using Langchain/rag_using_langchain.py"
```

**Security / hygiene**
- The autogenerated script currently contains an inline OpenAI API key copied from the notebook. Rotate or remove that key immediately and use environment variables or a `.env` file (the project already includes `python-dotenv` in the suggested deps).

**Troubleshooting**
- If transcripts are missing: some videos have captions disabled — the notebook handles `TranscriptsDisabled` and prints a message.
- If FAISS import or GPU issues appear: install the CPU-only PyTorch wheel or the appropriate FAISS package for your platform.
- If embeddings fail: confirm `sentence-transformers` model availability and sufficient RAM.

**Next steps / improvements**
- Persist the FAISS index to disk and add incremental updates for new videos.
- Add a simple web UI to submit queries and display source snippets (with timestamps and links to the original video).
- Improve the prompt template to include provenance (timestamps, chunk ids) so answers can cite sources.
- Swap the local embedding model for an API-backed embedding if you prefer managed embeddings.

**Wrap-up**
- This project demonstrates how a few well-chosen tools — caption ingestion, text splitting, semantic embeddings, and a vector index — can make long video content searchable and answerable. The repository contains both the exploratory notebook and an autogenerated script to make the pipeline easier to run.

If you'd like, I can:
- Remove the inline API key from `rag_using_langchain.py` and load it from a `.env`.
- Create a `requirements.txt` and add persistence for the FAISS index.
- Draft a short blog-ready HTML version or social post summarizing the project.
